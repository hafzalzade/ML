{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b413e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30. 100.]\n",
      " [ 20.  50.]\n",
      " [ 35.  72.]\n",
      " [ 25.  80.]\n",
      " [ 30.  70.]\n",
      " [ 40.  60.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data_origin = [[30, 100],\n",
    "               [20, 50],\n",
    "               [35, np.nan],\n",
    "               [25, 80],\n",
    "               [30, 70],\n",
    "               [40, 60]]\n",
    "\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(data_origin)\n",
    "data_mean_imp = imp_mean.transform(data_origin)\n",
    "print(data_mean_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2959e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30. 100.]\n",
      " [ 20.  50.]\n",
      " [ 35.  72.]\n",
      " [ 25.  80.]\n",
      " [ 30.  70.]\n",
      " [ 40.  60.]]\n"
     ]
    }
   ],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(data_origin)\n",
    "data_mean_imp = imp_mean.transform(data_origin)\n",
    "print(data_mean_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63427b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30. 100.]\n",
      " [ 20.  50.]\n",
      " [ 35.  70.]\n",
      " [ 25.  80.]\n",
      " [ 30.  70.]\n",
      " [ 40.  60.]]\n"
     ]
    }
   ],
   "source": [
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp_median.fit(data_origin)\n",
    "data_median_imp = imp_median.transform(data_origin)\n",
    "print(data_median_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c924285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20. 72.]\n",
      " [30. 72.]\n",
      " [30. 70.]\n",
      " [30. 72.]]\n"
     ]
    }
   ],
   "source": [
    "new = [[20, np.nan],\n",
    "       [30, np.nan],\n",
    "       [np.nan, 70],\n",
    "       [np.nan, np.nan]]\n",
    "new_mean_imp = imp_mean.transform(new)\n",
    "print(new_mean_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5b34d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 110\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "X_full, y = dataset.data, dataset.target\n",
    "\n",
    "\n",
    "\n",
    "m, n = X_full.shape\n",
    "m_missing = int(m * 0.25)\n",
    "print(m, m_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11da062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "missing_samples = np.array([True] * m_missing + [False] * (m - m_missing))\n",
    "np.random.shuffle(missing_samples)\n",
    "\n",
    "\n",
    "missing_features = np.random.randint(low=0, high=n, size=m_missing)\n",
    "\n",
    "X_missing = X_full.copy()\n",
    "X_missing[np.where(missing_samples)[0], missing_features] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7451919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm_missing = X_missing[~missing_samples, :]\n",
    "y_rm_missing = y[~missing_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e94738e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the data set with missing samples removed: 0.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "regressor = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=100)\n",
    "score_rm_missing = cross_val_score(regressor, X_rm_missing, y_rm_missing).mean()\n",
    "print(f'Score with the data set with missing samples removed: {score_rm_missing:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db470af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_mean_imp = imp_mean.fit_transform(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9070a7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the data set with missing values replaced by mean: 0.41\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=100)\n",
    "score_mean_imp = cross_val_score(regressor, X_mean_imp, y).mean()\n",
    "print(f'Score with the data set with missing values replaced by mean: {score_mean_imp:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "def704f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the full data set: 0.42\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=500)\n",
    "score_full = cross_val_score(regressor, X_full, y).mean()\n",
    "print(f'Score with the full data set: {score_full:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce7fc6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37c5deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the original data set: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = SVC(gamma=0.005, random_state=42)\n",
    "score = cross_val_score(classifier, X, y).mean()\n",
    "print(f'Score with the original data set: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f2e6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the original data set: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = SVC(gamma=0.005, random_state=42)\n",
    "score = cross_val_score(classifier, X, y).mean()\n",
    "print(f'Score with the original data set: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d868ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, criterion='gini', n_jobs=-1, random_state=42)\n",
    "random_forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0582dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sorted = np.argsort(random_forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39eb86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the dataset of top 10 features: 0.86\n",
      "Score with the dataset of top 15 features: 0.92\n",
      "Score with the dataset of top 25 features: 0.95\n",
      "Score with the dataset of top 35 features: 0.93\n",
      "Score with the dataset of top 45 features: 0.90\n",
      "Score with the dataset of top 65 features: 0.90\n",
      "Score with the dataset of top 85 features: 0.90\n"
     ]
    }
   ],
   "source": [
    "K = [10, 15, 25, 35, 45,65,85]\n",
    "for k in K:\n",
    "    top_K_features = feature_sorted[-k:]\n",
    "    X_k_selected = X[:, top_K_features]\n",
    "    # Estimate accuracy on the data set with k selected features\n",
    "    classifier = SVC(gamma=0.005)\n",
    "    score_k_features = cross_val_score(classifier, X_k_selected, y).mean()\n",
    "    print(f'Score with the dataset of top {k} features: {score_k_features:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82999158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the dataset of top 10 components: 0.94\n",
      "Score with the dataset of top 15 components: 0.95\n",
      "Score with the dataset of top 25 components: 0.93\n",
      "Score with the dataset of top 35 components: 0.91\n",
      "Score with the dataset of top 45 components: 0.90\n",
      "Score with the dataset of top 50 components: 0.90\n",
      "Score with the dataset of top 55 components: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Keep different number of top components\n",
    "N = [10, 15, 25, 35, 45,50,55]\n",
    "for n in N:\n",
    "    pca = PCA(n_components=n)\n",
    "    X_n_kept = pca.fit_transform(X)\n",
    "    # Estimate accuracy on the data set with top n components\n",
    "    classifier = SVC(gamma=0.005)\n",
    "    score_n_components = cross_val_score(classifier, X_n_kept, y).mean()\n",
    "    print(f'Score with the dataset of top {n} components: {score_n_components:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b459195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[4], [1], [3], [0]]\n",
    "binarizer = Binarizer(threshold=2.9)\n",
    "X_new = binarizer.fit_transform(X)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fd25945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  4.  4.  8. 16.]\n",
      " [ 1.  1.  3.  1.  3.  9.]\n",
      " [ 1.  3.  2.  9.  6.  4.]\n",
      " [ 1.  0.  3.  0.  0.  9.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = [[2, 4],\n",
    "     [1, 3],\n",
    "     [3, 2],\n",
    "     [0, 3]]\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_new = poly.fit_transform(X)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49c92ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ef36c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word computer is embedded into:\n",
      " [('camera', 0.907833456993103), ('cell', 0.891890287399292), ('server', 0.874466598033905), ('device', 0.8693525195121765), ('wifi', 0.863125741481781), ('screen', 0.8621907234191895), ('app', 0.8615543246269226), ('case', 0.8587921857833862), ('remote', 0.8583616018295288), ('file', 0.8575270771980286)]\n"
     ]
    }
   ],
   "source": [
    "vector = model.most_similar('computer')\n",
    "print('Word computer is embedded into:\\n', vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3df7e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words most contextually relevant to computer:\n",
      " [('camera', 0.907833456993103), ('cell', 0.891890287399292), ('server', 0.874466598033905), ('device', 0.8693525195121765), ('wifi', 0.863125741481781), ('screen', 0.8621907234191895), ('app', 0.8615543246269226), ('case', 0.8587921857833862), ('remote', 0.8583616018295288), ('file', 0.8575270771980286)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.most_similar(\"computer\")\n",
    "print('Top ten words most contextually relevant to computer:\\n', similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
